{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_dir = '/kaggle/input/cutmix-17march/cutmix_new/train'\ntest_dir = '/kaggle/input/cutmix-17march/cutmix_new/test'\n\n\nimg_height = 224\nimg_width = 224\nbatch_size = 32\n\n\npreprocess_input = tf.keras.applications.resnet.preprocess_input\n\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\nresnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\nfor layer in resnet_base.layers:\n    layer.trainable = False\n\nx = layers.Flatten()(resnet_base.output)\nx = layers.Dense(256, activation='relu')(x)\noutput = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = models.Model(inputs=resnet_base.input, outputs=output)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                    steps_per_epoch=None,  # Set to None to run until the generator stops\n                    epochs=10,\n                    validation_data=test_generator,\n                    validation_steps=None)  # Set to None to run until the generator stops\n\nloss, accuracy = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T10:52:37.079416Z","iopub.execute_input":"2024-03-17T10:52:37.079815Z","iopub.status.idle":"2024-03-17T11:45:24.909685Z","shell.execute_reply.started":"2024-03-17T10:52:37.079785Z","shell.execute_reply":"2024-03-17T11:45:24.907214Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-17 10:52:39.731316: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-17 10:52:39.731502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-17 10:52:39.926122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 1294 images belonging to 2 classes.\nFound 856 images belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 7s/step - accuracy: 0.5656 - loss: 16.6731 - val_accuracy: 0.8470 - val_loss: 0.6771\nEpoch 2/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 6s/step - accuracy: 0.8799 - loss: 0.4189 - val_accuracy: 0.8411 - val_loss: 0.3425\nEpoch 3/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 6s/step - accuracy: 0.9390 - loss: 0.1721 - val_accuracy: 0.8692 - val_loss: 0.2992\nEpoch 4/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 6s/step - accuracy: 0.9743 - loss: 0.0756 - val_accuracy: 0.8902 - val_loss: 0.3136\nEpoch 5/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - accuracy: 0.9758 - loss: 0.0858 - val_accuracy: 0.8867 - val_loss: 0.3239\nEpoch 6/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 7s/step - accuracy: 0.9856 - loss: 0.0556 - val_accuracy: 0.8680 - val_loss: 0.4290\nEpoch 7/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 6s/step - accuracy: 0.9851 - loss: 0.0550 - val_accuracy: 0.8984 - val_loss: 0.3208\nEpoch 8/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 7s/step - accuracy: 0.9884 - loss: 0.0298 - val_accuracy: 0.8995 - val_loss: 0.3101\nEpoch 9/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 6s/step - accuracy: 0.9978 - loss: 0.0129 - val_accuracy: 0.8995 - val_loss: 0.3345\nEpoch 10/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 7s/step - accuracy: 0.9874 - loss: 0.0521 - val_accuracy: 0.8937 - val_loss: 0.3372\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.8999 - loss: 0.3299\nTest Accuracy: 0.8936915993690491\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = '/kaggle/input/image-cutmix-predict/testing_cutmix.png'\n\nimg = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\nprediction = model.predict(img_array)\n\nif prediction < 0.5:\n    print(\"Original Image\")\nelse:\n    print(\"AI Generated Image\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:58:13.883178Z","iopub.execute_input":"2024-03-17T11:58:13.883702Z","iopub.status.idle":"2024-03-17T11:58:16.224842Z","shell.execute_reply.started":"2024-03-17T11:58:13.883656Z","shell.execute_reply":"2024-03-17T11:58:16.223409Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nAI Generated Image\n","output_type":"stream"}]}]}