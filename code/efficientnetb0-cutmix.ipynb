{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\n\n\ntrain_dir = '/kaggle/input/cutmix-17march/cutmix_new/train'\ntest_dir = '/kaggle/input/cutmix-17march/cutmix_new/test'\n\nimg_height = 224\nimg_width = 224\nbatch_size = 32\n\npreprocess_input = tf.keras.applications.efficientnet.preprocess_input\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\nefficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\nfor layer in efficientnet_base.layers:\n    layer.trainable = False\n\nx = layers.GlobalAveragePooling2D()(efficientnet_base.output)\nx = layers.Dense(256, activation='relu')(x)\noutput = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = models.Model(inputs=efficientnet_base.input, outputs=output)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                    steps_per_epoch=None,  # Set to None to run until the generator stops\n                    epochs=10,\n                    validation_data=test_generator,\n                    validation_steps=None)  # Set to None to run until the generator stops\n\nloss, accuracy = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T12:05:14.445460Z","iopub.execute_input":"2024-03-17T12:05:14.445889Z","iopub.status.idle":"2024-03-17T12:41:19.170255Z","shell.execute_reply.started":"2024-03-17T12:05:14.445857Z","shell.execute_reply":"2024-03-17T12:41:19.168436Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-17 12:05:16.530310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-17 12:05:16.530425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-17 12:05:16.676411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 1294 images belonging to 2 classes.\nFound 856 images belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - accuracy: 0.7000 - loss: 0.5619 - val_accuracy: 0.8727 - val_loss: 0.3138\nEpoch 2/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - accuracy: 0.8663 - loss: 0.3131 - val_accuracy: 0.8890 - val_loss: 0.2841\nEpoch 3/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - accuracy: 0.8976 - loss: 0.2599 - val_accuracy: 0.8925 - val_loss: 0.2750\nEpoch 4/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - accuracy: 0.9315 - loss: 0.2056 - val_accuracy: 0.9100 - val_loss: 0.2450\nEpoch 5/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9601 - loss: 0.1355 - val_accuracy: 0.9136 - val_loss: 0.2360\nEpoch 6/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.9683 - loss: 0.1234 - val_accuracy: 0.8645 - val_loss: 0.3682\nEpoch 7/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.9625 - loss: 0.1291 - val_accuracy: 0.8808 - val_loss: 0.3627\nEpoch 8/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9666 - loss: 0.1056 - val_accuracy: 0.9042 - val_loss: 0.2709\nEpoch 9/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9651 - loss: 0.0961 - val_accuracy: 0.9030 - val_loss: 0.2990\nEpoch 10/10\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9842 - loss: 0.0699 - val_accuracy: 0.8995 - val_loss: 0.3003\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8978 - loss: 0.2886\nTest Accuracy: 0.8995327353477478\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = '/kaggle/input/monalisa-predict-cutmix/monalisa.jpeg'\n\nimg = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\nprediction = model.predict(img_array)\n\nif prediction < 0.5:\n    print(\"AI generated Image\")\nelse:\n    print(\"Original Image\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T12:58:05.594964Z","iopub.execute_input":"2024-03-17T12:58:05.595458Z","iopub.status.idle":"2024-03-17T12:58:05.738468Z","shell.execute_reply.started":"2024-03-17T12:58:05.595426Z","shell.execute_reply":"2024-03-17T12:58:05.737529Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\nOriginal Image\n","output_type":"stream"}]}]}